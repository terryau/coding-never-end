!pip install tweet-preprocessor
import sklearn
import numpy as np
import pandas as pd
from numpy.random import RandomState

df = pd.read_csv('fomcRaw.csv', skiprows =[i for i in range(1,55)], index_col=0)

dfSort = df.head(61)
dfLabel = pd.read_csv('labelled.csv', index_col=0)

df = pd.concat([dfSort, dfLabel], axis=1)

train = df.sample(frac=0.5, random_state=rng)
test = df.loc[~df.index.isin(train.index)]

train.to_csv ('train.csv')
test.to_csv ('test.csv')

# training data
train = pd.read_csv("train.csv")

# test data
test = pd.read_csv("test.csv")

# remove special characters using the regular expression library
import re

#set up punctuations we want to be replaced
REPLACE_NO_SPACE = re.compile("(\.)|(\;)|(\:)|(\!)|(\')|(\?)|(\,)|(\")|(\|)|(\()|(\))|(\[)|(\])|(\%)|(\$)|(\>)|(\<)|(\{)|(\})")
REPLACE_WITH_SPACE = re.compile("(<br\s/><br\s/?)|(-)|(/)|(:).")

import preprocessor as p

# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)
def clean_content(df):
  tempArr = []
  for line in df:
    # send to tweet_processor
    tmpL = p.clean(line)
    # remove puctuation
    tmpL = REPLACE_NO_SPACE.sub("", tmpL.lower()) # convert all tweets to lower cases
    tmpL = REPLACE_WITH_SPACE.sub(" ", tmpL)
    tempArr.append(tmpL)
  return tempArr

# clean training data
train_content = clean_content(train["Content"])
train_content = pd.DataFrame(train_content)

# append cleaned tweets to the training data
train["clean_content"] = train_content

# compare the cleaned and uncleaned tweets
train.head()
